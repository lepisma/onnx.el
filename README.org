#+TITLE: onnx.el

ONNX runtime for Emacs Lisp. Primary motivation is to allow ML based text
operations inside Emacs, as much as possible, natively.

* Installation and Usage
There is a dynamic module that needs you to have [[https://onnxruntime.ai/][onnxruntime]] development package
installed for your distro. This module is automatically compiled when you
install the package using something like this:

#+begin_src emacs-lisp
(use-package onnx
  :vc (:fetcher github :repo lepisma/onnx.el)
  :demand t)
#+end_src

Note that this method only handles creating ~.so~ files which means it wonâ€™t work
on non-Linux systems yet. For other systems, manually inspect the ~Makefile~ and
compile the module yourself.

Once built and installed, you can load the package and use like the following:

#+begin_src emacs-lisp
  (require 'onnx)

  (setq model (onnx-load "path/to/model.onnx"))

  ;; Currently this package only supports CPU execution mode
  (onnx-run model `(("input-node-name" . ,input-matrix)) '("output-node-name"))
#+end_src

See ~./tests/~ directory for simple examples.

** Input & Output
This package only allows running ONNX models on numerical vectors. To do
anything meaningful with them, you will need to do some preprocessing and
postprocessing. For example to compute sentence embeddings and find similarity,
you will need to process text in tokens (ids) that your model can accept, and
then compute, say, cosine similarity on an index of output vectors. Here are a
few examples for this:

*** Sentence Transformers
In the first example we will run the [[https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/][all-MiniLM-L6-v2]] transformer model to get
embeddings of sentences.

The first step is to load the model which can be done like the following:
#+begin_src emacs-lisp
  ;; We assume the library is available in your load-path and you have downloaded
  ;; the necessary model onnx file
  (require 'onnx)
  (require 'onnx-ml-utils)
  (setq model (onnx-load "model_O2.onnx"))
#+end_src

Next we prepare the inputs using [[https://github.com/lepisma/tokenizers.el][tokenizers.el]]:
#+begin_src emacs-lisp
  (require 'tokenizers)

  ;; Model loading here happens via automatic http downloads
  ;; `encoding' is a list of token-ids, token-type-ids, and attention-mask
  (setq encoding (let ((tk (tokenizers-from-pretrained "sentence-transformers/all-MiniLM-L6-v2")))
                   (tokenizers-enable-padding tk 0 "[PAD]")
                   (tokenizers-encode-batch tk ["This is an example sentence" "Each sentence is converted"] t)))
  #+end_src

Finally, run the input via the model, mean pool, and then normalize to get
sentence embeddings:
#+begin_src emacs-lisp
  (let ((output (onnx-run model `(("input_ids" . ,(nth 0 encoding))
                                  ("token_type_ids" . ,(nth 1 encoding))
                                  ("attention_mask" . ,(nth 2 encoding)))
                          '("last_hidden_state"))))
    (setq output (onnx-ml-utils-nmean-pool output (nth 2 encoding)))
    (onnx-ml-utils-nl2-normalize output)
    output) ;; Shape N x D
#+end_src
